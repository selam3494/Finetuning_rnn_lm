{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knownski Challenge – Starter Walkthrough\n",
    "\n",
    "This notebook demonstrates a baseline approach to tackling the Knownski challenge. The goal is to build an AI agent capable of:\n",
    "\n",
    "1. **Understanding a GitHub issue and context** from a structured dataset.\n",
    "2. **Generating a code patch** that addresses the described issue.\n",
    "3. **Applying the patch** to the relevant repository and commit.\n",
    "4. **Running targeted tests** to confirm that failing tests now pass and previously passing tests remain green.\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "1. **Load and Inspect Dataset**\n",
    "   The dataset contains GitHub issues along with associated metadata:\n",
    "\n",
    "   * `repo` – Repository owner/name.\n",
    "   * `base_commit` – Commit SHA to apply the patch on.\n",
    "   * `problem_statement` – Description of the bug or feature request.\n",
    "   * `patch` – Ground-truth patch for training.\n",
    "   * `FAIL_TO_PASS` – Tests expected to fail before the fix.\n",
    "   * `PASS_TO_PASS` – Tests that should remain passing after the fix.\n",
    "\n",
    "2. **Model Preparation**\n",
    "   A code generation model (e.g., `unsloth/Qwen2.5-Coder-3B-Instruct-bnb-4bit`) is fine-tuned on issue–patch pairs using supervised fine-tuning (SFT).\n",
    "\n",
    "   * LoRA adapters are used to make fine-tuning efficient.\n",
    "   * Training is performed on the full set without splitting into validation if the dataset is very small.\n",
    "\n",
    "3. **Patch Generation**\n",
    "   The fine-tuned model is prompted with:\n",
    "\n",
    "   ```\n",
    "   ### GitHub Issue:\n",
    "   {problem_statement}\n",
    "\n",
    "   ### Patch:\n",
    "   ```\n",
    "\n",
    "   The generated output after `### Patch:` is used as the candidate fix.\n",
    "\n",
    "4. **Patch Application & Test Execution**\n",
    "\n",
    "   * Clone the target repository (skipping if already cloned locally).\n",
    "   * Checkout the specified `base_commit`.\n",
    "   * Apply the generated patch.\n",
    "   * Install dependencies and run the `FAIL_TO_PASS` tests (should now pass) and `PASS_TO_PASS` tests (should still pass).\n",
    "\n",
    "5. **Iterating and Improving**\n",
    "   While this notebook shows a simple end-to-end baseline, improvements may include:\n",
    "\n",
    "   * Better prompt engineering for patch generation.\n",
    "   * Incorporating retrieval of repository context before generation.\n",
    "   * Using reinforcement learning from test results to refine the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import tempfile\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import pipeline\n",
    "\n",
    "import wandb\n",
    "wandb.run = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passed and failed test content for a github issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/home/selu/Downloads/Interview_projects/knownski_challenge/data/data.parquet\")\n",
    "inst = df.query(\"instance_id=='pylint-dev__astroid-2496'\").iloc[0]\n",
    "instr = inst.problem_statement\n",
    "patch = inst.patch\n",
    "print(instr, patch, inst.FAIL_TO_PASS, inst.PASS_TO_PASS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune coding model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"text\": \"### Issue:\\n\" + row[\"problem_statement\"] + \"\\n### Patch:\\n\" + row[\"patch\"]}\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "ds_all = Dataset.from_list(examples)\n",
    "ds = DatasetDict({\"train\": ds_all})  # no split\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-Coder-3B-Instruct-bnb-4bit\",  # ASCII hyphens only\n",
    "    max_seq_length=1024,\n",
    "    load_in_4bit=True,\n",
    "    dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "    tok = tokenizer(ex[\"text\"], truncation=True, max_length=1024)\n",
    "    tok[\"labels\"] = tok.input_ids.copy()\n",
    "    return tok\n",
    "\n",
    "tok = ds.map(tokenize_fn, batched=False)\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/home/selu/Downloads/Interview_projects/knownski_challenge/patch_agent\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    logging_steps=20,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tok[\"train\"],\n",
    "    eval_dataset=None,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    packing=True,\n",
    "    args=args\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test runner & Patch applier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cmd_list, cwd=None):\n",
    "    \"\"\"Run a command as a list so special characters in test names don't break.\"\"\"\n",
    "    print(\"> \" + \" \".join(cmd_list))\n",
    "    result = subprocess.run(cmd_list, cwd=cwd)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Command failed with exit code {result.returncode}\")\n",
    "        sys.exit(result.returncode)\n",
    "\n",
    "def simplify_tests(test_list):\n",
    "    \"\"\"Return just the test file paths from full pytest node IDs.\"\"\"\n",
    "    return sorted({t.split(\"::\")[0] for t in test_list})\n",
    "\n",
    "def apply_instance(inst):\n",
    "    repo_url = f\"https://github.com/{inst.repo}.git\"\n",
    "    base = inst.base_commit\n",
    "    patch_text = inst.patch\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        os.chdir(tmp)\n",
    "\n",
    "        # Only clone if repo folder doesn't already exist\n",
    "        if not os.path.exists(\"repo\"):\n",
    "            run([\"git\", \"clone\", repo_url, \"repo\"])\n",
    "        else:\n",
    "            print(\"> Repo already cloned, skipping clone step.\")\n",
    "\n",
    "        os.chdir(\"repo\")\n",
    "        run([\"git\", \"checkout\", base])\n",
    "\n",
    "        # write and apply patch (ensure it ends with a newline)\n",
    "        with open(\"fix.patch\", \"w\") as f:\n",
    "            f.write(patch_text if patch_text.endswith(\"\\n\") else patch_text + \"\\n\")\n",
    "\n",
    "        # try a dry-run before applying\n",
    "        dry_run = subprocess.run([\"git\", \"apply\", \"--check\", \"fix.patch\"])\n",
    "        if dry_run.returncode != 0:\n",
    "            print(\"Patch is corrupt or context mismatch.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        run([\"git\", \"apply\", \"--recount\", \"--ignore-whitespace\", \"fix.patch\"])\n",
    "\n",
    "        # install requirements and pytest\n",
    "        run([sys.executable, \"-m\", \"pip\", \"install\", \"pytest\"])\n",
    "        if os.path.exists(\"requirements.txt\"):\n",
    "            run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "        else:\n",
    "            run([sys.executable, \"-m\", \"pip\", \"install\", \".\"])\n",
    "\n",
    "        # run tests by file\n",
    "        fail_files = simplify_tests(inst.FAIL_TO_PASS)\n",
    "        pass_files = simplify_tests(inst.PASS_TO_PASS)\n",
    "\n",
    "        print(\"\\n Running FAIL_TO_PASS tests (should now pass):\")\n",
    "        run([sys.executable, \"-m\", \"pytest\"] + fail_files)\n",
    "\n",
    "        print(\"\\n Running PASS_TO_PASS tests (should still pass):\")\n",
    "        run([sys.executable, \"-m\", \"pytest\"] + pass_files)\n",
    "\n",
    "        print(\"\\n All tests passed — patch applied cleanly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "def generate_patch(issue_text: str) -> str:\n",
    "    prompt = f\"### GitHub Issue:\\n{issue_text}\\n\\n### Patch:\\n\"\n",
    "    result = pipe(prompt, max_new_tokens=300, do_sample=True, top_p=0.9, temperature=0.8,\n",
    "                  pad_token_id=tokenizer.eos_token_id)\n",
    "    return result[0][\"generated_text\"].split(\"### Patch:\\n\", 1)[-1].strip()\n",
    "\n",
    "target = df.query(\"instance_id == 'pylint-dev__astroid-2496'\").iloc[0]\n",
    "\n",
    "row = SimpleNamespace(\n",
    "    repo=target.repo,\n",
    "    base_commit=target.base_commit,\n",
    "    patch=target.patch,\n",
    "    FAIL_TO_PASS=list(target.FAIL_TO_PASS),\n",
    "    PASS_TO_PASS=list(target.PASS_TO_PASS)\n",
    ")\n",
    "\n",
    "apply_instance(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQwQsB8jEMaV"
   },
   "source": [
    "## Positioning This as a Foundation for the 7‑Month Knownski Challenge\n",
    "\n",
    "The Knownski challenge runs over a 7‑month period, providing ample time to experiment, refine, and scale the solution.\n",
    "\n",
    "This notebook represents a **foundation** — a minimal, functional pipeline that can:\n",
    "\n",
    "* Load Knownski issue–patch data.\n",
    "* Fine-tune a code generation model on these examples.\n",
    "* Generate candidate patches.\n",
    "* Apply patches to the correct repository and commit.\n",
    "* Validate correctness via targeted tests.\n",
    "\n",
    "If I were starting the 7‑month journey, my **next immediate steps** from this foundation would be:\n",
    "\n",
    "1. **Expand the Training Data**\n",
    "\n",
    "   * Extract more issue–patch pairs from additional open-source repositories.\n",
    "   * Include variations and related bug contexts to improve generalization.\n",
    "\n",
    "2. **Use a More Powerful Base Model**\n",
    "\n",
    "   * Upgrade from the current 3B model to a larger, code-specialized model (e.g., 7B, 13B, or beyond), while still supporting LoRA fine-tuning for efficiency.\n",
    "\n",
    "3. **Advanced Fine-Tuning**\n",
    "\n",
    "   * Explore multi-turn fine-tuning with retrieval of relevant file context.\n",
    "   * Introduce reinforcement learning using test results as feedback (e.g., PPO).\n",
    "\n",
    "This notebook is **not** the final solution — it is the **launchpad**. It shows that the pipeline works end-to-end, and from here, the challenge becomes one of **scaling, improving accuracy, and automating context retrieval**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
