{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6dbbf8",
   "metadata": {},
   "source": [
    "# Look into the Shakespeare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac94875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 1115394\n",
      "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Sample text:\n",
      " First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n",
      "\n",
      "Example encoding/decoding:\n",
      "Original: To be or not to be\n",
      "Encoded: [32 53  1 40 43  1 53 56  1 52 53 58  1 58 53  1 40 43]\n",
      "Decoded: To be or not to be\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the Shakespeare text\n",
    "path = tf.keras.utils.get_file(\n",
    "    \"shakespeare.txt\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",
    ")\n",
    "text = Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Print some basic info\n",
    "print(\"Total characters:\", len(text))\n",
    "print(\"Unique characters:\", sorted(set(text)))\n",
    "print(\"Sample text:\\n\", text[:1000])  # first 1000 chars\n",
    "\n",
    "# Char to index and back\n",
    "vocab = sorted(set(text))\n",
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# Convert example string\n",
    "example = \"To be or not to be\"\n",
    "encoded = np.array([char2idx[c] for c in example])\n",
    "decoded = ''.join([idx2char[i] for i in encoded])\n",
    "\n",
    "print(\"\\nExample encoding/decoding:\")\n",
    "print(\"Original:\", example)\n",
    "print(\"Encoded:\", encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05effa",
   "metadata": {},
   "source": [
    "# Pretrained model output vs Fine tuned model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fb3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Output from Pretrained Base Model ---\n",
      "\n",
      "To be or not to be, to prey;\n",
      "What an the thrown made you?\n",
      "\n",
      "MERCIUT:\n",
      "Gentle, pale! yet you mean, sometime me to you,\n",
      "hin Gay behelk; coze and looks: while heaven armity,\n",
      "I make home from: there's to Rome, sir.\n",
      "\n",
      "otherful:\n",
      "Lady sake: no more.\n",
      "\n",
      "MISTRESS OVERDONA:\n",
      "What! justice she but but tender fronce.\n",
      "\n",
      "HAMY BETHA:\n",
      "Might hell loves her trut,--God, within this angle\n",
      "Be come. Must abused proverbled to.\n",
      "\n",
      "PERDITA:\n",
      "Ay, ay, \n",
      "\n",
      "--- Output from Fine-Tuned Model ---\n",
      "\n",
      "To be or not to be,\n",
      "And this impletered will but at his pair.\n",
      "\n",
      "First Condiner:\n",
      "Yet mad thee and my good lord.\n",
      "\n",
      "LEONTES:\n",
      "It will me good gone!\n",
      "Cfay was looks stabs to him, bedal our side.\n",
      "Give me any let me to alack grievour.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Sirt lose, thembereators so noteiff.\n",
      "My tresship is done and place to a grave\n",
      "And the soft\n",
      "May seem him confessiple, with urge desperrate\n",
      "Bohement hath Clifford's robe; and so it \n"
     ]
    }
   ],
   "source": [
    "# compare_models_output.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load raw text to rebuild vocab\n",
    "path = tf.keras.utils.get_file(\n",
    "    \"shakespeare.txt\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",
    ")\n",
    "text = Path(path).read_text(encoding=\"utf-8\")\n",
    "vocab = sorted(set(text))\n",
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# Text generation function\n",
    "def generate_text(model, start_string, gen_len=400):\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for _ in range(gen_len):\n",
    "        preds = model(input_eval)\n",
    "        preds = preds[:, -1, :]  # Get last timestep logits\n",
    "        pred_id = tf.random.categorical(preds, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.concat([input_eval, [[pred_id]]], axis=-1)\n",
    "        output.append(idx2char[pred_id])\n",
    "\n",
    "    return start_string + ''.join(output)\n",
    "\n",
    "# Load both models\n",
    "base_model = tf.keras.models.load_model(\"pretrained_best.keras\", compile=False)\n",
    "finetuned_model = tf.keras.models.load_model(\"finetuned_best.keras\", compile=False)\n",
    "\n",
    "# Run comparison\n",
    "prompt = \"To be or not to be,\"\n",
    "\n",
    "print(\"\\n--- Output from Pretrained Base Model ---\\n\")\n",
    "print(generate_text(base_model, prompt, gen_len=400))\n",
    "\n",
    "print(\"\\n--- Output from Fine-Tuned Model ---\\n\")\n",
    "print(generate_text(finetuned_model, prompt, gen_len=400))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e8560",
   "metadata": {},
   "source": [
    "#  Autoregressive Fine-Tuning Comparison: Shakespeare Char-RNN\n",
    "\n",
    "This experiment compares the text generation performance of a character-level RNN model **before and after fine-tuning** on a reserved portion of Shakespeare's corpus.\n",
    "\n",
    "## Prompt\n",
    "\n",
    "```text\n",
    "To be or not to be,\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Pretrained Base Model Output\n",
    "\n",
    "```\n",
    "To be or not to be, to prey;\n",
    "What an the thrown made you?\n",
    "\n",
    "MERCIUT:\n",
    "Gentle, pale! yet you mean, sometime me to you,\n",
    "hin Gay behelk; coze and looks: while heaven armity,\n",
    "I make home from: there's to Rome, sir.\n",
    "\n",
    "otherful:\n",
    "Lady sake: no more.\n",
    "\n",
    "MISTRESS OVERDONA:\n",
    "What! justice she but but tender fronce.\n",
    "\n",
    "HAMY BETHA:\n",
    "Might hell loves her trut,--God, within this angle\n",
    "Be come. Must abused proverbled to.\n",
    "\n",
    "PERDITA:\n",
    "Ay, ay, \n",
    "```\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* Contains valid Shakespearean character formatting and line breaks.\n",
    "* Semantically chaotic and often nonsensical.\n",
    "* High rate of word mashups and grammar errors (e.g., *“abused proverbled”*, *“hin Gay behelk”*).\n",
    "* Lacks dramatic coherence and thematic flow.\n",
    "\n",
    "---\n",
    "\n",
    "### Fine-Tuned Model Output\n",
    "\n",
    "```\n",
    "To be or not to be,\n",
    "And this impletered will but at his pair.\n",
    "\n",
    "First Condiner:\n",
    "Yet mad thee and my good lord.\n",
    "\n",
    "LEONTES:\n",
    "It will me good gone!\n",
    "Cfay was looks stabs to him, bedal our side.\n",
    "Give me any let me to alack grievour.\n",
    "\n",
    "DUKE OF YORK:\n",
    "Sirt lose, thembereators so noteiff.\n",
    "My tresship is done and place to a grave\n",
    "And the soft\n",
    "May seem him confessiple, with urge desperrate\n",
    "Bohement hath Clifford's robe; and so it\n",
    "```\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* Mimics Shakespearean syntax and rhythm more convincingly.\n",
    "* Dramatic progression and emotion are better represented.\n",
    "* Made-up words (*“confessiple”*, *“noteiff”*) still appear, but with contextual flavor.\n",
    "* Character interactions are more coherent and structured.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The **fine-tuned model** produces outputs that are significantly more stylistically faithful to Shakespearean drama. While both models hallucinate words, the fine-tuned version demonstrates:\n",
    "\n",
    "* Improved structure and scene formatting\n",
    "* Sharper emotional tone\n",
    "* More plausible pseudo-Elizabethan phrasing\n",
    "\n",
    "Fine-tuning elevated the model from *\"bard-core gibberish\"* to *\"plausible lost play fragment.\"*\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a59385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9002e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ec107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561db214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b305701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed5173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
